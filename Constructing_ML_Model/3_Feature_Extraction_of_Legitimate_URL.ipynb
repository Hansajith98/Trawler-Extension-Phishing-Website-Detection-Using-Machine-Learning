{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Extraction of ` Legitimate URLs `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGqrU8U-IcKJ"
   },
   "outputs": [],
   "source": [
    "#importing required packages for this module\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J1vIfCbPawl"
   },
   "source": [
    "# **2.2. Legitimate URLs:**\n",
    "From the uploaded Begin_list_big_final.csv file, the URLs are loaded into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_SDdAYKQU1BO",
    "outputId": "6d0bb923-3e16-4aee-f022-a98ea2218d78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://graphicriver.net/search?date=this-month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://ecnavi.jp/redirect/?url=http://www.cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hubpages.com/signin?explain=follow+Hub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://extratorrent.cc/torrent/4190536/AOMEI+B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://icicibank.com/Personal-Banking/offers/o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  http://graphicriver.net/search?date=this-month...\n",
       "1  http://ecnavi.jp/redirect/?url=http://www.cros...\n",
       "2  https://hubpages.com/signin?explain=follow+Hub...\n",
       "3  http://extratorrent.cc/torrent/4190536/AOMEI+B...\n",
       "4  http://icicibank.com/Personal-Banking/offers/o..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the benigan URLs data to dataframe\n",
    "legiurl = pd.read_csv(\"4-beniganurl.csv\")\n",
    "legiurl.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTxZ_n_QaSiQ"
   },
   "source": [
    "# **3.Feature Extraction**\n",
    "In this step,features are extracted from the URLs dataset.\n",
    "The extracted features are categorized into\n",
    "\n",
    "\n",
    "1.   Address Bar based Features\n",
    "2.   Domain based Features\n",
    "3.   HTML & Javascript Features\n",
    "\n",
    "## **3.1.Address Bar Based Features:**\n",
    "Many features can be extracted that can be consided as address bar base them, below mentioned were considered for this project.\n",
    "\n",
    "\n",
    "*   Domain of URL \n",
    "*   IP Address in URL\n",
    "*   \"@\"Symbol in URL\n",
    "* Length of URL\n",
    "* Depth of URL\n",
    "* Redirection \"//\" in URL\n",
    "* \"http/https\" in Domain name\n",
    "* Using URL Shortening Services \"TinyURL\"\n",
    "* Prefix or Suffix \"-\" in Domain\n",
    "\n",
    "Each of these features are explained and the coded below:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYoTVys1qn3M"
   },
   "outputs": [],
   "source": [
    "#importing required packages for this section\n",
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "import urllib.request\n",
    "import ipaddress\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsSKK_2ZrJyh"
   },
   "source": [
    "# **3.1.1.Domain of the URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYfndKCqvZHw"
   },
   "outputs": [],
   "source": [
    "# 1.Domain of the URL(Domain) \n",
    "def getDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if re.match(r\"^www.\",domain):\n",
    "       domain = domain.replace(\"www.\",\"\")\n",
    "  return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhMCQQuDwQ_Y"
   },
   "source": [
    "# **3.1.2.IP Address in the URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYgGJqfSwcAh"
   },
   "outputs": [],
   "source": [
    "# 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Srx9LROYwmTx"
   },
   "source": [
    "# **3.1.3. \"@\" Symbol in URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrkEy_hDwqtL"
   },
   "outputs": [],
   "source": [
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1    \n",
    "  else:\n",
    "    at = 0    \n",
    "  return at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuj4cJIkwuuN"
   },
   "source": [
    "# **3.1.4. Length of URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjPLVb0vw0Fl"
   },
   "outputs": [],
   "source": [
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0            \n",
    "  else:\n",
    "    length = 1            \n",
    "  return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87aenLF6w7DB"
   },
   "source": [
    "# **3.1.5. Depth of URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRmDYHCLw_kS"
   },
   "outputs": [],
   "source": [
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diaAscAhxD7P"
   },
   "source": [
    "# **3.1.6. Redirection \"//\" in URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvgWnWm3xKHt"
   },
   "outputs": [],
   "source": [
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QK1Tr3x4xMtV"
   },
   "source": [
    "# **3.1.7. \"http/https\" in Domain name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4l3mXyNyxRIK"
   },
   "outputs": [],
   "source": [
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA_R8DuTxY9b"
   },
   "source": [
    "# **3.1.8. Using URL Shortening Services “TinyURL”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ntj-SW8Zxg2W"
   },
   "outputs": [],
   "source": [
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-znXXb9GxkKI"
   },
   "outputs": [],
   "source": [
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPlogJR7xoia"
   },
   "source": [
    "# **3.1.9. Prefix or Suffix \"-\" in Domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB_dy3iLxv1m"
   },
   "outputs": [],
   "source": [
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sONp0BY_xxM2"
   },
   "source": [
    "## **3.2. Domain Based Features:**\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "\n",
    "*  DNS Record\n",
    "* Website Traffic\n",
    "*Age of Domain\n",
    "*End Period of Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eI_Vv-DtyY1a"
   },
   "source": [
    "**3.2.1.DNS Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HT5kdpgygtV"
   },
   "outputs": [],
   "source": [
    "# 11.DNS Record availability (DNS_Record)\n",
    "# obtained in the featureExtraction function itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mfi8JU6Gykkt"
   },
   "source": [
    "**3.2.2. Web Traffic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8eYJ1y4yvcv"
   },
   "outputs": [],
   "source": [
    "# 12.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "  try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "    url = urllib.parse.quote(url)\n",
    "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "    rank = int(rank)\n",
    "  except TypeError:\n",
    "        return 1\n",
    "  if rank <100000:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx_qCM6ay5Ss"
   },
   "source": [
    "**3.2.3. Age of Domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9MXrS7xy85G"
   },
   "outputs": [],
   "source": [
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yITvAvN-zCFQ"
   },
   "source": [
    "**3.2.4. End Period of Domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeEgia6AzGS5"
   },
   "outputs": [],
   "source": [
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR1vLK0uzLaM"
   },
   "source": [
    "# **3.3. HTML and JavaScript based Features**\n",
    "Many features can be extracted that come under this category. Out of them, below mentioned were considered for this project.\n",
    "\n",
    "\n",
    "\n",
    "*  IFrame Redirection\n",
    "*Status Bar Customization\n",
    "*Disabling Right Click\n",
    "*Website Forwarding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCDTDLJ-z34Q"
   },
   "source": [
    "### **3.3.1. IFrame Redirection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "si_MpmcH0DRW"
   },
   "outputs": [],
   "source": [
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YsTyQaK0H_4"
   },
   "source": [
    "### **3.3.2. Status Bar Customization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXLz5ZW-0Lvt"
   },
   "outputs": [],
   "source": [
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vox0qZ5K0O5J"
   },
   "source": [
    "### **3.3.3. Disabling Right Click**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Y34TPkq0WJ6"
   },
   "outputs": [],
   "source": [
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbc83e1U0e4U"
   },
   "source": [
    "### **3.3.4. Website Forwarding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6Rhym1o0ggJ"
   },
   "outputs": [],
   "source": [
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5GcTic00kyr"
   },
   "source": [
    "## **4. Computing URL Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LCBt9d40mMw"
   },
   "outputs": [],
   "source": [
    "#Function to extract features\n",
    "def featureExtraction(url,label):\n",
    "\n",
    "  features = []\n",
    "  #Address bar based features (10)\n",
    "  features.append(getDomain(url))\n",
    "  features.append(havingIP(url))\n",
    "  features.append(haveAtSign(url))\n",
    "  features.append(getLength(url))\n",
    "  features.append(getDepth(url))\n",
    "  features.append(redirection(url))\n",
    "  features.append(httpDomain(url))\n",
    "  features.append(tinyURL(url))\n",
    "  features.append(prefixSuffix(url))\n",
    "  \n",
    "  #Domain based features (4)\n",
    "  dns = 0\n",
    "  try:\n",
    "    domain_name = whois.whois(urlparse(url).netloc)\n",
    "  except:\n",
    "    dns = 1\n",
    "\n",
    "  features.append(dns)\n",
    "  features.append(web_traffic(url))\n",
    "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "  \n",
    "  # HTML & Javascript based features (4)\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except:\n",
    "    response = \"\"\n",
    "  features.append(iframe(response))\n",
    "  features.append(mouseOver(response))\n",
    "  features.append(rightClick(response))\n",
    "  features.append(forwarding(response))\n",
    "  features.append(label)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXbG7vN50uuY"
   },
   "source": [
    "### **4.1. Reviewing Legitimate URLs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctCOq0Rr0vr5"
   },
   "outputs": [],
   "source": [
    "legiurl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhNJjEVagMXS"
   },
   "source": [
    "We will Reviewing URls 2500 by 2500 and storing seperate files and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cL8d6Y6MgiRm"
   },
   "outputs": [],
   "source": [
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n",
    "label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vo5VyvfhYYl"
   },
   "source": [
    "0 - 5000 legitmate URLs Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tr6jt4fN0y-3"
   },
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "legi_features = []\n",
    "\n",
    "for i in range(0, 5000):\n",
    "  url = legiurl['URLs'][i]\n",
    "  print(i)\n",
    "  legi_features.append(featureExtraction(url,label))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml-WwPeJ01Vy"
   },
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "legitimate = pd.DataFrame(legi_features, columns= feature_names)\n",
    "legitimate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6ctlOzQ05QU"
   },
   "outputs": [],
   "source": [
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "legitimate.to_csv('6-legitimate_features.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributors - Deshitha Hansajith [Linked In](https://www.linkedin.com/in/deshitha-hansajith/), Nipuni Dilukshika [Linked In](https://www.linkedin.com/in/nipuni-dilukshika-186764197/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3-Feature_Extraction_of_Legitimate_URL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
